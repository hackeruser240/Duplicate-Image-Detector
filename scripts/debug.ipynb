{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db86932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import sys\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1674f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_hashes(directory, hash_size=8, hash_method='dhash'):\n",
    "    \"\"\"\n",
    "    Recursively walks through a directory, computes a perceptual hash for each\n",
    "    image file, and stores it in the global image_hashes dictionary.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): The path to the directory to scan.\n",
    "        hash_size (int): The size of the hash, which can affect precision.\n",
    "                         A larger size (e.g., 16) is more precise but slower.\n",
    "        hash_method (str): The hashing algorithm to use ('phash', 'ahash', 'dhash').\n",
    "                           'phash' is recommended for its robustness.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are image hashes and values are a list of\n",
    "              file paths that share that hash.\n",
    "    \"\"\"\n",
    "    print(f\"Scanning directory: {directory}\")\n",
    "    \n",
    "    # Reset the global dictionary for each new scan\n",
    "    global image_hashes\n",
    "    image_hashes = {}\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            \n",
    "            # Check if the file is an image based on its extension\n",
    "            if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    # Convert to RGB to ensure compatibility with imagehash, as some\n",
    "                    # images might be in a different mode (e.g., RGBA, L).\n",
    "                    img = img.convert('RGB')\n",
    "                    \n",
    "                    # Compute the hash using the specified method\n",
    "                    if hash_method == 'phash':\n",
    "                        image_hash = imagehash.phash(img, hash_size=hash_size)\n",
    "                    elif hash_method == 'ahash':\n",
    "                        image_hash = imagehash.average_hash(img, hash_size=hash_size)\n",
    "                    elif hash_method == 'dhash':\n",
    "                        image_hash = imagehash.dhash(img, hash_size=hash_size)\n",
    "                    else:\n",
    "                        print(f\"Error: Unsupported hash method '{hash_method}'. Using phash instead.\")\n",
    "                        image_hash = imagehash.phash(img, hash_size=hash_size)\n",
    "\n",
    "                    # Store the hash and file path. The hash is converted to a string\n",
    "                    # to be used as a dictionary key.\n",
    "                    hash_str = str(image_hash)\n",
    "                    if hash_str in image_hashes:\n",
    "                        image_hashes[hash_str].append(file_path)\n",
    "                    else:\n",
    "                        image_hashes[hash_str] = [file_path]\n",
    "            \n",
    "            except Exception as e:\n",
    "                # Catch any errors during image processing or file access\n",
    "                print(f\"Could not process file {file_path}: {e}\", file=sys.stderr)\n",
    "                continue\n",
    "    \n",
    "    print(\"Scanning complete.\")\n",
    "    return image_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "501f4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_item=[]\n",
    "def find_duplicates(hashes_map, threshold=10):\n",
    "    \"\"\"\n",
    "    Finds groups of exact and near-duplicate images based on their hashes.\n",
    "    \n",
    "    Args:\n",
    "        hashes_map (dict): The dictionary of hashes and file paths returned by\n",
    "                           get_image_hashes.\n",
    "        threshold (int): The maximum allowed Hamming distance for two images\n",
    "                         to be considered near-duplicates. A value of 0 means\n",
    "                         only exact duplicates are found.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of lists, where each inner list represents a group of\n",
    "              duplicate image file paths.\n",
    "    \"\"\"\n",
    "    duplicates = []\n",
    "    processed_hashes = set()\n",
    "    \n",
    "    # Iterate through all hashes to find duplicates\n",
    "    for hash_str, file_paths in hashes_map.items():\n",
    "        # Skip hashes that have already been processed as part of another group\n",
    "        if hash_str in processed_hashes:\n",
    "            continue\n",
    "        \n",
    "        current_group = file_paths[:]\n",
    "        processed_hashes.add(hash_str)\n",
    "        \n",
    "        # Check for near-duplicates if the threshold is greater than 0\n",
    "        if threshold > 0:\n",
    "            for other_hash_str, other_file_paths in hashes_map.items():\n",
    "                if hash_str != other_hash_str and other_hash_str not in processed_hashes:\n",
    "                    try:\n",
    "                        # Compute the Hamming distance between two hashes\n",
    "                        hash1 = imagehash.hex_to_hash(hash_str)\n",
    "                        hash2 = imagehash.hex_to_hash(other_hash_str)\n",
    "                        if hash1 - hash2 <= threshold:\n",
    "                            current_group.extend(other_file_paths)\n",
    "                            processed_hashes.add(other_hash_str)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error comparing hashes: {e}\", file=sys.stderr)\n",
    "                        continue\n",
    "\n",
    "        if len(current_group) > 1:\n",
    "            duplicates.append(current_group)\n",
    "    \n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45979af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def delete_duplicates(duplicate_groups, deletion_strategy='keep_first'):\n",
    "    \"\"\"\n",
    "    Deletes duplicate images from the disk based on a chosen strategy.\n",
    "    \n",
    "    Args:\n",
    "        duplicate_groups (list): A list of duplicate groups, as returned by\n",
    "                                 find_duplicates.\n",
    "        deletion_strategy (str): The strategy to determine which image to keep.\n",
    "                                 'keep_first' is the default.\n",
    "    \"\"\"\n",
    "    if not duplicate_groups:\n",
    "        print(\"No duplicate images to delete.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nFound {len(duplicate_groups)} duplicate groups.\")\n",
    "    \n",
    "    files_to_delete = []\n",
    "    \n",
    "    # Determine which files to delete based on the strategy\n",
    "    for group in duplicate_groups:\n",
    "        first_item.append(group[0])\n",
    "\n",
    "        if deletion_strategy == 'keep_first':\n",
    "            # Keep the first image found in the group\n",
    "            files_to_delete.extend(group[1:])\n",
    "        elif deletion_strategy == 'keep_smallest':\n",
    "            # Keep the image with the smallest file size\n",
    "            files_and_sizes = [(path, os.path.getsize(path)) for path in group]\n",
    "            files_and_sizes.sort(key=lambda x: x[1])\n",
    "            files_to_delete.extend([path for path, _ in files_and_sizes[1:]])\n",
    "        else:\n",
    "            print(f\"Error: Unsupported deletion strategy '{deletion_strategy}'. Using 'keep_first'.\")\n",
    "            files_to_delete.extend(group[1:])\n",
    "    \n",
    "        \n",
    "    # Print a summary of files to be deleted (Dry Run)\n",
    "    print(\"\\n--- Dry Run: Files to be deleted ---\")\n",
    "    for item in first_item:\n",
    "        for file in files_to_delete:\n",
    "            print(f\"{item}: {file}\")\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "    # Prompt user for confirmation before deletion\n",
    "    response = input(f\"\\nAre you sure you want to delete {len(files_to_delete)} files? (yes/no): \").lower()\n",
    "    \n",
    "    if response == 'yes' or 'y':\n",
    "        deleted_count = 0\n",
    "        for file_path in files_to_delete:\n",
    "            try:\n",
    "                # Use os.remove to delete the file\n",
    "                os.remove(file_path)\n",
    "                deleted_count += 1\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Error deleting {file_path}: {e}\", file=sys.stderr)\n",
    "        \n",
    "        print(f\"\\nSuccessfully deleted {deleted_count} files.\")\n",
    "    else:\n",
    "        print(\"Deletion cancelled by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83015f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: D:\\Pictures\\Bears\n",
      "Scanning complete.\n"
     ]
    }
   ],
   "source": [
    "image_hashes=get_image_hashes(r\"D:\\Pictures\\Bears\")\n",
    "#print(f\"image_hashes:{image_hashes}\")\n",
    "\n",
    "duplicates_=find_duplicates(image_hashes)\n",
    "#print(duplicates_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1db1faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['D:\\\\Pictures\\\\Bears\\\\10.jpg', 'D:\\\\Pictures\\\\Bears\\\\2.jpg'],\n",
       " ['D:\\\\Pictures\\\\Bears\\\\13.jpg', 'D:\\\\Pictures\\\\Bears\\\\24.jpg'],\n",
       " ['D:\\\\Pictures\\\\Bears\\\\14 - Copy (2).jpg',\n",
       "  'D:\\\\Pictures\\\\Bears\\\\14 - Copy.jpg',\n",
       "  'D:\\\\Pictures\\\\Bears\\\\14.jpg'],\n",
       " ['D:\\\\Pictures\\\\Bears\\\\15 - Copy.jpg', 'D:\\\\Pictures\\\\Bears\\\\15.jpg'],\n",
       " ['D:\\\\Pictures\\\\Bears\\\\16 - Copy.jpg', 'D:\\\\Pictures\\\\Bears\\\\16.jpg'],\n",
       " ['D:\\\\Pictures\\\\Bears\\\\23.jpg', 'D:\\\\Pictures\\\\Bears\\\\7.jpg'],\n",
       " ['D:\\\\Pictures\\\\Bears\\\\26.jpg', 'D:\\\\Pictures\\\\Bears\\\\5.jpg']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_\n",
    "first_item=[ group[0] for group in duplicates_ ]\n",
    "\n",
    "duplicates_\n",
    "#first_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f19145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Pictures\\Bears\\10.jpg:['D:\\\\Pictures\\\\Bears\\\\2.jpg']\n",
      "D:\\Pictures\\Bears\\13.jpg:['D:\\\\Pictures\\\\Bears\\\\24.jpg']\n",
      "D:\\Pictures\\Bears\\14 - Copy (2).jpg:['D:\\\\Pictures\\\\Bears\\\\14 - Copy.jpg', 'D:\\\\Pictures\\\\Bears\\\\14.jpg']\n",
      "D:\\Pictures\\Bears\\15 - Copy.jpg:['D:\\\\Pictures\\\\Bears\\\\15.jpg']\n",
      "D:\\Pictures\\Bears\\16 - Copy.jpg:['D:\\\\Pictures\\\\Bears\\\\16.jpg']\n",
      "D:\\Pictures\\Bears\\23.jpg:['D:\\\\Pictures\\\\Bears\\\\7.jpg']\n",
      "D:\\Pictures\\Bears\\26.jpg:['D:\\\\Pictures\\\\Bears\\\\5.jpg']\n"
     ]
    }
   ],
   "source": [
    "for group in duplicates_:\n",
    "    group.sort()\n",
    "    print(f\"{group[0]}:{group[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692973cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
